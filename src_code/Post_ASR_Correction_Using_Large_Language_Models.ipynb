{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%capture/\n",
        "%pip install accelerate bitsandbytes transformers trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "import json\n",
        "import numpy as np \n",
        "from jiwer import wer\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading LLaMa 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#LoRA Configuration Parameters\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.1\n",
        "RANK = 64  # The rank for the low-rank matrices\n",
        "BIAS_MODE = \"none\"  # Indicates whether to include bias in the LoRA adaptation\n",
        "TASK_TYPE = \"CAUSAL_LM\"  # The type of task for the model adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### --Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model from Hugging Face hub\n",
        "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# New instruction dataset\n",
        "guanaco_dataset = \"mlabonne/guanaco-llama2-1k\"\n",
        "\n",
        "# Fine-tuned model\n",
        "new_model = \"llama-2-7b-chat-cornell\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### -- Loading the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our case, we create 4-bit quantization with NF4 type configuration using BitsAndBytes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Quanitization Configuration \n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af1570eebd5c4620a85509968e250f15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0},\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will load the tokenizer from Hugginface and set padding_side to “right” to fix the issue with fp16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def llama_gensec(line):\n",
        "    few_shot_prompt = \"\"\"<s>[INST] You need to do language model rescoring in ASR. Given the 5-best hypotheses, you need to report the true transcription from the 5-best hypotheses. DO NOT WRITE ANYTHING BESIDES THE true hypothesis absolutely nothing else. Just simply say the true hypothesis. Don't say you can help me with this or anything like that. Just say the true hypothesis. your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. If none of the hypotheses make sense just generate one that is logical. YOU MUST SAY \"The true hypothesis is:\" followed by the hypothesis.\n",
        "\n",
        "    Here are some examples of what you might take as an input: (REMEMBER THESE ARE JUST EXAMPLES, SO THEY ARE NOT THE SAME AS THE INPUT YOU WILL RECEIVE.)\n",
        "    \n",
        "    Speech recognition: \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july onest\"\n",
        "    Truth: The true hypothesis is: list the flights from dallas to baltimore arriving july first\n",
        "\n",
        "\n",
        "    Speech recognition: \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june ten\", \"i would like to fly from san diego to houston on june ten\"\n",
        "    Truth: The true hypothesis is: i would like to fly from san diego to houston on june tenth\n",
        "\n",
        "    Speech recognition: \"list flights from houston to memphis june twenty-nineth\", \"list flights from houston to memphis june twenty-nineth\", \"list flights from houston to memphis june twenty-nine\", \"list flights from houston to memphis june twenty-nineth\", \"list flights from houston to memphis june twenty-nineth\" \n",
        "    Truth: list flights from houston to memphis june twenty ninth\"\n",
        "\n",
        "    Speech recognition: \"about half these managers are in the u s\", \"about half these managers are in the us\", \"about half these managers are in the us\", \"about half these managers are in the us\", \"about half of these managers are in the us\"\n",
        "    Truth: about half these managers are in the us\n",
        "\n",
        "\n",
        "    Don't say you can help me with this or please provide the true hypothesis. Just say the true hypothesis AND DO NOT ADD ANY IRRELEVANT INFORMATION. Your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. If none of the hypotheses make sense just generate one that is logical. YOU MUST SAY \"Truth: The true hypothesis is:\" followed by the hypothesis.\n",
        " \"\"\"\n",
        "\n",
        "    return few_shot_prompt + line + \"[/INST] Truth: The true hypothesis is: \"\n",
        "\n",
        "# some other examples to consider using \n",
        "\n",
        "# \"\"\"\n",
        "# Speech recognition: \"list all us air flights from miami to cleveland leaving on sunday afternoon\", \"list all us air flights from miami to cleveland leaving on sunday afternoon\", \"list all us air flights from miami to cleveland leaving on sunday afternoon\", \"list all us airflights from miami to cleveland leaving on sunday afternoon\", \"list all us airflights from miami to cleveland leaving on sunday afternoon\n",
        "# Truth: The true hypothesis is: list all u s air flights from miami to cleveland leaving on sunday afternoon\"\n",
        "\n",
        "\n",
        "# Speech recognition: \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july onest\"\n",
        "# Truth: The true hypothesis is: list the flights from dallas to baltimore arriving july first\n",
        "\n",
        "\n",
        "# Speech recognition: \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june ten\", \"i would like to fly from san diego to houston on june ten\"\n",
        "# Truth: The true hypothesis is: i would like to fly from san diego to houston on june tenth\n",
        "\n",
        "\n",
        "# Speech recognition: \"the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous arson last year\", \"the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous auction last year\", \"the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous arson last year\", \"the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous auction last year\", \"the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous auction last year\"\n",
        "#     Truth: the average rate on new thirteen week treasury bills increased to six point one two percent from five point nine seven percent at the previous auction last week\n",
        "    \n",
        "#     Speech recognition: \"the investor now owns seventy-three percent of the company\", the investor now owns seventy-three percent of the company, the investor now owns seventy-three per cent of the company, the investor now owns seventy three percent of the company, the investments are now on seventy-three percent of the company\n",
        "#     Truth: the investor now owns seventy three percent of the company\n",
        "\n",
        "#     Speech recognition: \"at nec the need for international mergers will keep rising\", \"at nec the need for international mergers will keep rising\", \"at nec the need for international mergers will keep rising\", \"at nec the need for international mergers will keep rising\", \"at nec the need for international mergers will keep rising\"\n",
        "#     Truth: at n e c the need for international managers will keep rising\n",
        "\n",
        "# \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda:0\"\n",
        "with open(\"test_chime4.json\") as jsonFile:\n",
        "    test_data = json.load(jsonFile)\n",
        "\n",
        "llama_df = pd.DataFrame(columns=['input', 'output', 'prediction', 'match'])\n",
        "punctuation_to_remove = ',.\\\"!?:;$'\n",
        "punctuation_to_replace = '-'\n",
        "\n",
        "for question in test_data:\n",
        "    hypotheses = question['input']\n",
        "    test_txt = \"\"\n",
        "    for line in hypotheses:\n",
        "        test_txt += line + '\\n'\n",
        "    \n",
        "    inputs = tokenizer(llama_gensec(test_txt), return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "    res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    try:\n",
        "        res = res.split('[/INST] Truth: ')[2].split('The true hypothesis is:')[1].translate(\n",
        "            str.maketrans('', '', punctuation_to_remove)).translate(str.maketrans(punctuation_to_replace, ' ')).strip().lower()\n",
        "    except IndexError:\n",
        "        res = \"No valid hypothesis found\"\n",
        "    \n",
        "    truth = \"Yes\" if res == question['output'].strip().lower() else \"No\"\n",
        "    llama_df = llama_df._append({'input': test_txt, 'prediction': res, 'output': question['output'], 'match': truth}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'llama_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllama_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llama_df' is not defined"
          ]
        }
      ],
      "source": [
        "llama_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "llama_df.to_csv('llama_gosec.csv', index=False)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/g7/anaconda3/envs/finetuning_whisper/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/home/g7/anaconda3/envs/finetuning_whisper/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7add69223a544e8d8d3181afd4a3f6e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id = \"google/gemma-7b-it\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "hf_token = \"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\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, use_auth_token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gemma_gensec(line):\n",
        "    few_shot_prompt = \"\"\"<start_of_turn>user You need to do language model rescoring in ASR. Given the 5-best hypotheses, you need to report the true transcription from the 5-best hypotheses. DO NOT WRITE ANYTHING BESIDES THE true hypothesis absolutely nothing else. Just simply say the true hypothesis. Don't say you can help me with this or anything like that. Just say the true hypothesis. your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. If none of the hypotheses make sense just generate one that is logical. YOU MUST SAY \"The true hypothesis is:\" followed by the hypothesis.\n",
        "\n",
        "\n",
        "    Here are some examples of what you might take as an input:\n",
        "\n",
        "    <start_of_turn>user \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july onest\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july one\", \"list the flights from dallas to baltimore arriving july onest\"\n",
        "    <start_of_turn>model The true hypothesis is: list the flights from dallas to baltimore arriving july first<end_of_turn>\n",
        "\n",
        "\n",
        "    <start_of_turn>user \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june tenth\", \"i would like to fly from san diego to houston on june ten\", \"i would like to fly from san diego to houston on june ten\"\n",
        "    <start_of_turn>model The true hypothesis is: i would like to fly from san diego to houston on june tenth<end_of_turn>\n",
        "\n",
        "    Don't say you can help me with this or please provide the true hypothesis. Just say the true hypothesis. your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. If none of the hypotheses make sense just generate one that is logical. YOU MUST SAY \"The true hypothesis is:\" followed by the hypothesis.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "    return \"<start_of_turn>user\" + few_shot_prompt + line + \"[/INST]<start_of_turn>model The true hypothesis is: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[146], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     17\u001b[0m res \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[/INST]model The true hypothesis is: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, punctuation_to_remove))\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(punctuation_to_replace, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m gemma_df \u001b[38;5;241m=\u001b[39m gemma_df\u001b[38;5;241m.\u001b[39m_append({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m:test_txt,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m:res,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m:question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch\u001b[39m\u001b[38;5;124m'\u001b[39m:truth},ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\"\n",
        "with open(\"test_chime4.json\") as jsonFile:\n",
        "  test_data = json.load(jsonFile)\n",
        "example_dir = \"/home/g7/Hyporadise-icl/examples/knn/\"\n",
        "train_data = json.load(open(\"train_chime4.json\",'r'))\n",
        "\n",
        "gemma_df = pd.DataFrame(columns=['input','output','prediction','match'])\n",
        "punctuation_to_remove = ',.\\\"!$?*'\n",
        "punctuation_to_replace = '-'\n",
        "for question in test_data:\n",
        "        hypotheses = question['input']\n",
        "        test_txt = \"\"\n",
        "        for line in hypotheses:\n",
        "            test_txt += line + '\\n'\n",
        "        inputs = tokenizer(gemma_gensec(test_txt), return_tensors=\"pt\").to(device)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "        res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        res = res.split('[/INST]model The true hypothesis is: ')[1].translate(str.maketrans('', '', punctuation_to_remove)).translate(str.maketrans(punctuation_to_replace, ' ')).strip().lower().split('\\n')[0]\n",
        "        \n",
        "        truth = \"Yes\" if res == question['output'].strip() else \"No\"\n",
        "        gemma_df = gemma_df._append({'input':test_txt,'prediction':res,'output':question['output'],'match':truth},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'gemma_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgemma_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead() \n",
            "\u001b[0;31mNameError\u001b[0m: name 'gemma_df' is not defined"
          ]
        }
      ],
      "source": [
        "gemma_df.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "gemma_df.to_csv('gemma_gemsec.csv', index=False)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fff97e279ec44b0a8cd5f320e8ee31ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    device_map={\"\":0},\n",
        "    quantization_config=nf4_config,\n",
        "    use_cache=False\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GENSEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mistral_gensec(line):\n",
        "    few_shot_prompt = \"\"\"For the following task nothing may be generated besides what I say do not say \"OK\" or sure or anything else do simply the task NOTHING BEFORE IT AND NOTHING AFTER IT. You need to do language model rescoring in ASR. Given the 5-best hypotheses, you need to report the true transcription from the 5-best hypotheses. DO NOT WRITE ANYTHING BESIDES THE true hypothesis absolutely nothing else. Just simply say the true hypothesis. Don't say you can help me with this or anything like that. Just say the true hypothesis. your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. If none of the hypotheses make sense just generate one that is logical. At the end of the input, you will receive \"Truth: \", AND YOU MUST COMPLETE IT BY SAYING \"The true hypothesis is:\" followed by the hypothesis AND nothing else before it or after it. Dont confirm dont say \"sure\" dont say youll do it just simply but the hypothesis or you will be marked as incorrect.\n",
        "\n",
        "   Here are some examples of what will happen as you can see NOTHING IS PUT BEFORE OR AFTER THE HYPOTHESIS and there is never a \"sure\" or \"ill do that\" BECAUSE ITS WRONG:\n",
        "    Speech recognition: list all us air flights from miami to cleveland leaving on sunday afternoon\n",
        "    list all us air flights from miami to cleveland leaving on sunday afternoon\n",
        "    list all us air flights from miami to cleveland leaving on sunday afternoon\n",
        "    list all us airflights from miami to cleveland leaving on sunday afternoon\n",
        "    list all us airflights from miami to cleveland leaving on sunday afternoon\n",
        "    Truth: The true hypothesis is: list all u s air flights from miami to cleveland leaving on sunday afternoon\n",
        "\n",
        "    Speech recognition: list the flights from dallas to baltimore arriving july onest\n",
        "    list the flights from dallas to baltimore arriving july onest\n",
        "    list the flights from dallas to baltimore arriving july one\n",
        "    list the flights from dallas to baltimore arriving july one\n",
        "    list the flights from dallas to baltimore arriving july onest\n",
        "    Truth: The true hypothesis is: list the flights from dallas to baltimore arriving july first\n",
        "\n",
        "    Speech recognition: realized capital gains increased forty-two percent to $nine hundred and nine million from $six hundred and forty point nine million\n",
        "    realized capital gains increased forty-two percent to nine hundred and nine million dollars from six hundred and forty point nine million dollars\n",
        "    realized capital gains increased forty-two percent to $nine hundred and nine million from $six hundred and forty point nine million\n",
        "    realized capital gains increased forty-two percent to nine hundred and nine million dollars from six hundred and forty point nine million dollars\n",
        "    realized capital gains increased forty-two percent from $six hundred and nine million to $six hundred and forty point nine million\n",
        "    Truth: The true hypothesis is: realized capital gains increased forty two percent to nine hundred nine million dollars from six hundred forty point nine million dollars\n",
        "\n",
        "    Speech recognition: i would like to fly from san diego to houston on june tenth\n",
        "    i would like to fly from san diego to houston on june tenth\n",
        "    i would like to fly from san diego to houston on june tenth\n",
        "    i would like to fly from san diego to houston on june ten\n",
        "    i would like to fly from san diego to houston on june ten\n",
        "    Truth: The true hypothesis is: i would like to fly from san diego to houston on june tenth\n",
        "\n",
        "    Just say the true hypothesis. Your output should be a single sentence and that sentence should be the prediction it is important that you do not write anything else besides the true hypothesis as it will all be added to a csv file and we need to make sure that the csv file is correct. DONT EVEN CONFIRM JUST PUT THE RESPONSE. Noting that these responses are coming from an ASR and hence may be completely incorrect and noting that the input may be related to a previous input and hence follows the same formats for correct responses, If none of the hypotheses make sense just generate one that is logical, this can sometimes be done by combining the correct parts of the inputs. YOU MUST SAY 'The true hypothesis is:' followed by the hypothesis. Nothing additional before or after it.\n",
        " \"\"\"\n",
        "\n",
        "    return few_shot_prompt + \"Speech recognition: \" + line + \"\\nTruth: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "with open(\"test_chime4.json\") as jsonFile:\n",
        "  test_data = json.load(jsonFile)\n",
        "example_dir = \"/home/g7/Hyporadise-icl/examples/knn/\"\n",
        "train_data = json.load(open(\"train_chime4.json\",'r'))\n",
        "\n",
        "mistral_df = pd.DataFrame(columns=['input','output','prediction','match'])\n",
        "punctuation_to_remove = ',.\\\"!$?*'\n",
        "punctuation_to_replace = '-'\n",
        "for question in test_data:\n",
        "        hypotheses = question['input']\n",
        "        test_txt = \"\"\n",
        "        for line in hypotheses:\n",
        "            test_txt += line + '\\n'\n",
        "        pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=10000)\n",
        "        pipe = pipe(f\"<s>[INST] {mistral_gensec(test_txt)} [/INST]\")\n",
        "        #print(pipe[0]['generated_text'])\n",
        "        res = pipe[0]['generated_text'].split('[/INST]  The true hypothesis is:')[1].translate(str.maketrans('', '', punctuation_to_remove)).translate(str.maketrans(punctuation_to_replace, ' ')).strip().lower().split('\\n')[0]\n",
        "        #print(res)\n",
        "        truth = \"Yes\" if res == question['output'].strip() else \"No\"\n",
        "        mistral_df = mistral_df._append({'input':test_txt,'prediction':res,'output':question['output'],'match':truth},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mistral_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "mistral_df.to_csv('mistral_gensec.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculate WER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_wer(x):\n",
        "    try:\n",
        "        return wer(x[\"output\"], x[\"prediction\"])\n",
        "    except Exception as e:\n",
        "        \n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loading data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(name):\n",
        "    df_dict = dict()\n",
        "    for file in os.listdir(name):\n",
        "        dir = os.path.join(name, file)\n",
        "        df = pd.read_csv(dir)\n",
        "        df_dict[file] = df\n",
        "    return df_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating WERs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n",
            "input nan was expected to be a string or list of strings\n"
          ]
        }
      ],
      "source": [
        "llama_dfs = load_data('../llama')\n",
        "# main_df = load_data('Test')\n",
        "gemma_dfs = load_data('../gemma')\n",
        "mistral_dfs = load_data('../mistral')\n",
        "mistral_means = {}\n",
        "gemma_means = {}\n",
        "llama_means = {}\n",
        "\n",
        "for key, gemma_df in gemma_dfs.items():\n",
        "      \n",
        "    gemma_df[\"wer\"] = gemma_df.apply(calculate_wer, axis=1)\n",
        "    gemma_WER = gemma_df[\"wer\"].mean()\n",
        "    gemma_means[key] = gemma_WER\n",
        "\n",
        "for key, mistral_df in mistral_dfs.items():  \n",
        "    mistral_df[\"wer\"] = mistral_df.apply(calculate_wer, axis=1)\n",
        "    mistral_WER = mistral_df[\"wer\"].mean()\n",
        "    mistral_means[key] = mistral_WER\n",
        "\n",
        "for key, llama_df in llama_dfs.items():  \n",
        "    llama_df[\"wer\"] = llama_df.apply(calculate_wer, axis=1)\n",
        "    llama_WER = llama_df[\"wer\"].mean()\n",
        "    llama_means[key] = llama_WER\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final WERs for each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'td3.csv': 0.23790247349885943,\n",
              " 'atis.csv': 0.1374393413080562,\n",
              " 'swbd.csv': 0.33769704497062514,\n",
              " 'coraal.csv': 0.3564330426005726,\n",
              " 'cv.csv': 0.2179936719734514,\n",
              " 'wsj_score.csv': 0.0828399469799684,\n",
              " 'ls_clean.csv': 0.13662836528319475,\n",
              " 'lrs2.csv': 0.5654393657192575,\n",
              " 'chime4.csv': 0.1362669753160008,\n",
              " 'ls_other.csv': 0.17189414675217798}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "    \n",
        "gemma_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'td3.csv': 0.12014224300933046,\n",
              " 'atis.csv': 0.053993816555395584,\n",
              " 'swbd.csv': 0.24747948811904963,\n",
              " 'coraal.csv': 0.2949800790480015,\n",
              " 'cv.csv': 0.15620163553766497,\n",
              " 'wsj_score.csv': 0.049385817805383564,\n",
              " 'ls_clean.csv': 0.03628464454401195,\n",
              " 'lrs2.csv': 0.1510749629999668,\n",
              " 'chime4.csv': 0.09346733959529634,\n",
              " 'ls_other.csv': 0.06225450389373135}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'td3.csv': 0.4403438675349629,\n",
              " 'atis.csv': 0.2942612153113435,\n",
              " 'swbd.csv': 0.5507895004516763,\n",
              " 'coraal.csv': 0.6627389853584942,\n",
              " 'cv.csv': 0.4219997086915543,\n",
              " 'wsj_score.csv': 0.14830265274341953,\n",
              " 'ls_clean.csv': 0.18250998429772702,\n",
              " 'lrs2.csv': 0.7108412413372655,\n",
              " 'chime4.csv': 0.4318291851207352,\n",
              " 'ls_other.csv': 0.24317990283458094}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "llama_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_means = {\n",
        "    'test_test_atis.json': 0.0880,\n",
        "    'test_test_chime4.json': 0.1174,\n",
        "    'test_test_coraal.json': 0.2456,\n",
        "    'test_test_cv.json': 0.1752,\n",
        "    'test_test_lrs2.json': 0.1528,\n",
        "    'test_test_ls_clean.json': 0.0877,\n",
        "    'test_test_ls_other.json': 0.1080,\n",
        "    'test_test_swbd.json': 0.1793,\n",
        "    'test_test_td3.json': 0.0497,\n",
        "    'test_test_wsj_score.json': 0.0627\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average WER LLaMa: 0.24317990283458094, Average WER Mistral: 0.06225450389373135, Average WER Gemma: 0.17189414675217798\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# main_df[\"wer\"] = main_df.apply(calculate_wer, axis=1)\n",
        "\n",
        "# main_df = main_df[\"wer\"].mean()\n",
        "\n",
        "llama_df[\"wer\"] = llama_df.apply(calculate_wer, axis=1)\n",
        "llama_WER = llama_df[\"wer\"].mean()\n",
        "\n",
        "# llama_WER = 0\n",
        "mistral_df[\"wer\"] = mistral_df.apply(calculate_wer, axis=1)\n",
        "\n",
        "mistral_WER = mistral_df[\"wer\"].mean()\n",
        "\n",
        "gemma_df[\"wer\"] = gemma_df.apply(calculate_wer, axis=1)\n",
        "gemma_WER = gemma_df[\"wer\"].mean()\n",
        "\n",
        "\n",
        "print(f\"Average WER LLaMa: {llama_WER}, Average WER Mistral: {mistral_WER}, Average WER Gemma: {gemma_WER}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_dfs = dict()\n",
        "\n",
        "for key, mistral_df in mistral_dfs.items(): \n",
        "    final_df = pd.DataFrame(columns=['input','output','prediction','match'])\n",
        "    \n",
        "    for index, row in mistral_df.iterrows():\n",
        "        if pd.isna(llama_dfs[key].iloc[index]['prediction']):\n",
        "            continue\n",
        "        if row['prediction'] == gemma_dfs[key].iloc[index]['prediction'] or row['prediction'] == llama_dfs[key].iloc[index]['prediction']:\n",
        "            final_df = final_df._append({'input':row['input'],'output':row['output'],'prediction':row['prediction'],'match':row['output']},ignore_index=True)\n",
        "        elif gemma_dfs[key].iloc[index]['prediction'] == llama_dfs[key].iloc[index]['prediction']:\n",
        "            final_df = final_df._append({'input':gemma_dfs[key].iloc[index]['input'],'output':gemma_dfs[key].iloc[index]['output'],'prediction':gemma_dfs[key].iloc[index]['prediction'],'match':gemma_dfs[key].iloc[index]['match']},ignore_index=True)\n",
        "        else:\n",
        "            final_df = final_df._append({'input':row['input'],'output':row['output'],'prediction':row['prediction'],'match':row['match']},ignore_index=True)\n",
        "    final_dfs[key] = final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'td3.csv': 0.1134362067987092,\n",
              " 'atis.csv': 0.053504958762725846,\n",
              " 'swbd.csv': 0.24670022852859794,\n",
              " 'coraal.csv': 0.2895052105007568,\n",
              " 'cv.csv': 0.15584858267752455,\n",
              " 'wsj_score.csv': 0.04715481497559449,\n",
              " 'ls_clean.csv': 0.03352807131122364,\n",
              " 'lrs2.csv': 0.14875409461831576,\n",
              " 'chime4.csv': 0.09138065443162978,\n",
              " 'ls_other.csv': 0.06070991386194508}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_means = {}\n",
        "for key, final_df in final_dfs.items():  \n",
        "    final_df[\"wer\"] = final_df.apply(calculate_wer, axis=1)\n",
        "    final_WER = final_df[\"wer\"].mean()\n",
        "    ensemble_means[key] = final_WER\n",
        "ensemble_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### WER for ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average WER ensemble: 0.06070991386194508\n"
          ]
        }
      ],
      "source": [
        "final_df[\"wer\"] = final_df.apply(calculate_wer, axis=1)\n",
        "final_WER = final_df[\"wer\"].mean()\n",
        "print(f\"Average WER ensemble: {final_WER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final_df.to_csv('final_gensec.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# WER values\n",
        "# llama_WER = 0.35717688949068566\n",
        "# mistral_WER = 0.13613660533613253\n",
        "# gemma_WER = 0.24675227978705616\n",
        "# ensemble_WER = 0.12851217699576528\n",
        "# Models and their WER values\n",
        "llama_WER = np.array(list(llama_means.values())).mean()\n",
        "mistral_WER = np.array(list(mistral_means.values())).mean()\n",
        "gemma_WER = np.array(list(gemma_means.values())).mean()\n",
        "ensemble_WER = np.array(list(ensemble_means.values())).mean()\n",
        "bl_wer = np.array(list(test_means.values())).mean()\n",
        "\n",
        "models = ['BaseLine','LLAMA', 'Mistral', 'Gemma', 'Ensemble']\n",
        "wer_values = [bl_wer, llama_WER, mistral_WER, gemma_WER, final_WER]\n",
        "\n",
        "colors = ['#666666', '#666666', '#666666', '#666666', '#666666']\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, wer_values, color=colors)\n",
        "\n",
        "plt.title('Average Word Error Rate (WER) for Each Model', color='black')\n",
        "plt.xlabel('Models', color='black')\n",
        "plt.ylabel('Average WER', color='black')\n",
        "\n",
        "# Save the bar chart as a PNG file\n",
        "plt.savefig('results.png')\n",
        "\n",
        "# Display the bar chart\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
